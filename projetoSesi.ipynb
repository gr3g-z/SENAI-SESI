{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gr3g-z/SENAI-SESI/blob/main/projetoSesi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-NuHPcg335"
      },
      "source": [
        "# Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cz8T-WLg336"
      },
      "source": [
        "## 1.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whpHcS98g337"
      },
      "source": [
        "Cada país origem deve ter seu próprio diretório e dentro dele subdiretórios para os países destino, e dentro deles os arquivos nomeados com as datas da consulta.\n",
        "Manter a organização por país de origem e destino aumenta a eficiência do conjunto de dados e facilita requesições e manuteções futuras.\n",
        "ex:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2py2Io9Dg337"
      },
      "outputs": [],
      "source": [
        "/base_comex/\n",
        "    ├── [BRA]/\n",
        "    │   ├── [AFG]/\n",
        "    │   │   ── 2019.txt\n",
        "    │   │   ── 2020.txt\n",
        "    │   │   ── 2021.txt\n",
        "    │   ├── [ARG]/\n",
        "    │   │   ── 2019.txt\n",
        "    │   │   ── 2020.txt\n",
        "    │   │   ── 2021.txt\n",
        "    │   │\n",
        "    ├── [CHN]/\n",
        "         [...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwPwGI7ig338"
      },
      "source": [
        "## 1.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCc88m5Pg338"
      },
      "source": [
        "Inicialmente seria necessário fazer um request na API e para isso seria preciso configura-la.\n",
        "- Utilizando Python podemos importar a biblioteca Requests e OS para fazer uma requisição na API e incluir dados no diretório."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfpK2i9Ag338"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN-OImzgg338"
      },
      "outputs": [],
      "source": [
        "# API\n",
        "API_ENDPOINT = \"https://api.comercioexterior.com/consulta\"# Endereço da API\n",
        "API_KEY = \"PASSWORD_123\"# Chave da API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz-WSAj1g338"
      },
      "source": [
        "Após configurar a API\n",
        "\n",
        "- Criar uma lista com os Países Origem a partir da organização de pastas do diretório.\n",
        "Todas as pastas subsequentes de base_comex serão um país origem, logo, é possível pegar o nome de todas elas e inserir em uma lista para que possamos iterar sobre eles posteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiVgYeRIg339"
      },
      "outputs": [],
      "source": [
        "def lista_paises_origem(base_path):\n",
        "    try:\n",
        "\n",
        "        pastas = [nome for nome in os.listdir(base_path)\n",
        "                   if os.path.isdir(os.path.join(base_path, nome))]\n",
        "        return sorted(pastas)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao listar pastas: {e}\")\n",
        "        return []\n",
        "\n",
        "path = '/caminho/para/base_comex'\n",
        "\n",
        "# Obtem a lista de países de origem\n",
        "paises_origem = lista_paises_origem(path) #variavel com a lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blRbRGYMg339"
      },
      "outputs": [],
      "source": [
        "# Função para consultar API e salvar dados\n",
        "def get_dados(pais_origem, pais_destino, ano):\n",
        "    params = {\n",
        "        'pais_origem': pais_origem,\n",
        "        'pais_destino': pais_destino,\n",
        "        'ano': ano,\n",
        "        'api_key': API_KEY\n",
        "    }#Dicionário com os parâmetros da consulta\n",
        "    attempts = 3\n",
        "    for attempt in range(attempts):\n",
        "        response = requests.get(API_ENDPOINT, params=params)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            print(f\"Erro na consulta {pais_origem}-{pais_destino}-{ano}: {response.status_code}\")\n",
        "            time.sleep(5)  # Esperar antes de tentar novamente\n",
        "    return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wzf81G_g339"
      },
      "source": [
        "Função que cria a estrutura de diretórios necessária para armazenar os dados.\n",
        "Cria diretórios para todas as combinações de países de origem e destino, exceto quando são iguais caso os diretórios não existam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIwnKLezg339"
      },
      "outputs": [],
      "source": [
        "def criar_estrutura_diretorios(path):\n",
        "    for pais_origem in lista_paises:\n",
        "        for pais_destino in lista_paises:\n",
        "            if pais_origem != pais_destino:\n",
        "                path = os.path.join(path, pais_origem, pais_destino)\n",
        "                os.makedirs(path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6xQCnPeg339"
      },
      "outputs": [],
      "source": [
        "# Criar estrutura de diretórios\n",
        "criar_estrutura_diretorios(path)\n",
        "\n",
        "# Iterar sobre países de origem, destinos e anos para fazer consultas e salvar dados\n",
        "for pais_origem in paises_origem:\n",
        "    for pais_destino in paises_origem:\n",
        "        if pais_origem != pais_destino:\n",
        "            for ano in anos:\n",
        "                dados = get_dados(pais_origem, pais_destino, ano)\n",
        "                if dados:\n",
        "                    # Caminho do arquivo onde os dados serão salvos\n",
        "                    file_path = os.path.join(path, pais_origem, pais_destino, f\"{ano}.txt\")\n",
        "                    with open(file_path, 'w') as file:\n",
        "                        file.write(str(dados))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ27ENkeg33-"
      },
      "source": [
        "Podemos Dividir o Código em 5 Etapas\n",
        "\n",
        "- 1 - **Configurações Iniciais:** Configurações da API.\n",
        "- 2 - **Lista Países de Origem:** Obtém a lista de países de origem baseada na estrutura de diretórios existente.\n",
        "- 3 - **Consulta API:** Define uma função para fazer consultas na API com várias tentativas em caso de falha.\n",
        "- 4 - **Cria Diretórios:** Cria a estrutura de diretórios necessária para armazenar os dados caso não existam.\n",
        "- 5 - **Itera e Consulta:** Itera sobre todos os países de origem, destino e anos, faz consultas na API, e salva os dados em arquivos organizados por diretórios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QLY9PA5g33-"
      },
      "source": [
        "## 1.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si4rGu-Og33-"
      },
      "source": [
        "A resposta estaria em:\n",
        "\n",
        "<td>\n",
        "/base_comex/BRA/WLD/2020.txt\n",
        "</td>\n",
        "\n",
        "Pois BRA seria o país de origem, WLD o destino e neste caso o WLD representa o comércio enviado ao Mundo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2-KIH-Zg33-"
      },
      "source": [
        "## 1.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd1KCgsvg33-"
      },
      "source": [
        "O ideal seria Atualizar a base Mensalmente.\n",
        "Considerando que estamos no Inicio de Fevereiro de 2025, os dados de 2024 já devem estar disponíveis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AUeX5v6g33-"
      },
      "source": [
        "Etapa 1 - Verificar e Atualizar Dados Mensais para 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJDffYppg33-"
      },
      "outputs": [],
      "source": [
        "# TENDO EM VISTA QUE TEMOS ESTA FUNÇÃO PARA SALVAR OS DADOS\n",
        "def salvar_dados(mes_ou_tipo, dados):\n",
        "    # Caminho do arquivo baseado no tipo de dado (mensal ou anual) e no mês\n",
        "    path = '/caminho/para/base_comex/BRA/CHN/'\n",
        "    if mes_ou_ano == 'anual':\n",
        "        file_path = os.path.join(path, '2024', 'final.txt')\n",
        "    else:\n",
        "        file_path = os.path.join(path, '2024', f'{mes_ou_ano}.txt')\n",
        "\n",
        "    # Salvar dados no arquivo\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(str(dados))  # Ajuste conforme necessário (por exemplo, JSON, CSV, etc.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huC21WBMg33-"
      },
      "source": [
        "Executar consultas com Parâmetro M para cada mês de 2024 para garantir que as informações estejam completas até fevereiro de 2025."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eosak2wPg33_"
      },
      "outputs": [],
      "source": [
        "def atualizar_dados_mensais(ano):\n",
        "    meses = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
        "    for mes in meses:\n",
        "        dados = get_dados(pais_origem, pais_destino, ano, 'M', mes)\n",
        "        salvar_dados(mes, dados)\n",
        "\n",
        "atualizar_dados_mensais(2024)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9hMNtZ7g33_"
      },
      "source": [
        "Etapa 2 - Verificar e Atualizar os dados anuais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKChk5hFg33_"
      },
      "outputs": [],
      "source": [
        "def atualizar_dados_anuais(ano):\n",
        "    dados = get_dados(pais_origem, pais_destino, ano, 'A')\n",
        "    salvar_dados('final', dados)\n",
        "\n",
        "atualizar_dados_anuais(2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4OJFOkmg33_"
      },
      "source": [
        "Etapa 3 - Armazenar os Dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnFvmC7vg33_"
      },
      "outputs": [],
      "source": [
        "/base_comex/\n",
        "    ├── [BRA]/\n",
        "    │   ├── [ARG]/\n",
        "    │   │   ├── 2024/\n",
        "    │   │   │   ├── 01.txt\n",
        "    │   │   │   ├── 02.txt\n",
        "    │   │   │   ├── ...\n",
        "    │   │   │   └── Anual.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pmLBfrFg33_"
      },
      "source": [
        "Etapa 4 - Agendamento de Consultas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYeYgNSAg33_"
      },
      "source": [
        "Definir datas para realizar as consultas de forma Automatizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMzjbuqpg33_"
      },
      "source": [
        "Acredito que o melhor caminho seja utilizar o CRON do Linux e agendar uma consulta dentro de uma VM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4DjS7XAg34A"
      },
      "source": [
        "Porém aqui esta uma maneira alternativa com código Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stDS-knyg34A"
      },
      "outputs": [],
      "source": [
        "import schedule\n",
        "import time\n",
        "\n",
        "def tarefa_diaria():\n",
        "    atualizar_dados_mensais(2025)\n",
        "\n",
        "def tarefa_trimestral():\n",
        "    atualizar_dados_anuais(2025)\n",
        "\n",
        "schedule.every().day.at(\"07:00\").do(tarefa_diaria)\n",
        "schedule.every().three_months.do(tarefa_trimestral)\n",
        "\n",
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awijnwfHg34A"
      },
      "source": [
        "Etapa 5 - Verificar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYW623aLg34A"
      },
      "source": [
        "É muito importante evitar dados inconsistentes então seria interessante comparar os dados anuais com os mensais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsn0VqZgg34A"
      },
      "source": [
        "Etapa 6 - Manter logs de manutenção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twMdj6ydg34A"
      },
      "source": [
        "# Questão 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzG5HXP0g34A"
      },
      "source": [
        "Etapas para manter o dataset de empresas atualizado:\n",
        "\n",
        "- 1 - Baixar Arquivos\n",
        "- 2 - Extrair Arquivos\n",
        "- 3 - Empilhar Arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhabaEv1g34A"
      },
      "outputs": [],
      "source": [
        "def baixar_arquivos():\n",
        "    for i in range(10):\n",
        "        url = f'http://200.152.38.155/CNPJ/{i}.zip'\n",
        "        response = requests.get(url)\n",
        "        with open(f'arquivos/{i}.zip', 'wb') as arquivo:\n",
        "            arquivo.write(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZWtMNpCg34B"
      },
      "outputs": [],
      "source": [
        "def extrair_arquivos():\n",
        "    for i in range(10):\n",
        "        with zipfile.ZipFile(f'arquivos/{i}.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall(f'arquivos_extraidos/{i}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWjynXw7g34E"
      },
      "outputs": [],
      "source": [
        "def empilhar_arquivos():\n",
        "    df_list = []\n",
        "    for i in range(10):\n",
        "        df = pd.read_csv(f'arquivos_extraidos/{i}/arquivo.csv')\n",
        "        df_list.append(df)\n",
        "    df_final = pd.concat(df_list, ignore_index=True)\n",
        "    df_final.to_csv('dataset_final.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy1iz8Vig34E"
      },
      "source": [
        "# Questão 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t6rhqgUg34E"
      },
      "outputs": [],
      "source": [
        "\n",
        "SELECT\n",
        "    e.employee_name,\n",
        "    (SELECT d.department_name\n",
        "     FROM departments d\n",
        "     JOIN employee_department_history edh ON d.department_id = edh.department_id\n",
        "     WHERE edh.employee_id = e.employee_id\n",
        "     ORDER BY edh.start_date ASC\n",
        "     LIMIT 1) AS first_department,\n",
        "    (SELECT d.department_name\n",
        "     FROM departments d\n",
        "     JOIN employee_department_history edh ON d.department_id = edh.department_id\n",
        "     WHERE edh.employee_id = e.employee_id AND edh.end_date IS NULL) AS current_department,\n",
        "    COUNT(DISTINCT edh.department_id) AS total_departments\n",
        "FROM employees e\n",
        "JOIN employee_department_history edh ON e.employee_id = edh.employee_id\n",
        "GROUP BY e.employee_id, e.employee_name;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjBrbopKg34F"
      },
      "source": [
        "# Questão 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojEABQfKg34F"
      },
      "source": [
        "Seria interessante particionar o arquivo, ter o aquivo em menores frações pode ser vantajoso para ler somente aquilo que sera necessário e criar indices a partir de uma tabela de mapeamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34RA-Doig34F"
      },
      "source": [
        "# Questão 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCYVcDJfg34F"
      },
      "source": [
        "**Engenharia de Features**\n",
        "- Criar novas variáveis a partir das existentes.\n",
        "\n",
        "**Normalização dos Dados**\n",
        "- Padronizar as variáveis para melhorar a performance do modelo.\n",
        "\n",
        "**Especificação do Modelo**\n",
        "- Revisar se o modelo indicado é o ideal para o problema\n",
        "\n",
        "**Validação Cruzada**\n",
        "- Garantie que o modelo não está com overfitting ou underfitting nos dados.\n",
        "\n",
        "**Revisão do Contexto Econômico**\n",
        "- Certificar que o modelo econométrico está fundamentado na teoria econômica correta.\n",
        "\n",
        "Consultoria e Revisão\n",
        "- Pedir a revisão do seu trabalho por outros especialistas/colegas para obter ajudas e sugestões.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi1o6Etpg34F"
      },
      "source": [
        "# Questão 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1lIsWIDg34F"
      },
      "source": [
        "Supondo que só uma seja verdadeira.\n",
        "\n",
        "- a) Falso\n",
        "- b) Falso\n",
        "- c) Falso\n",
        "- d) Verdadeiro\n",
        "- e) Falso"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}